set.seed(1)
# train_grid <- expand.grid(.mtry = seq(2, ncol(data_x), 1))
train_grid <- expand.grid(.mtry = seq(2, ncol(data_x), 1))
train_params <- trainControl(method = "repeatedcv",
number = 50,
repeats = 10,
savePredictions = TRUE,
summaryFunction = expRMSE,
verboseIter = TRUE)
train_model <- train(y = log(data_y),
x = data_x,
ntree=5000,
metric = "expRMSE",
maximize = FALSE,
tuneGrid = train_grid,
trControl = train_params)
train_model
head(data_x)
plot(train_model)
data <- read.csv("train.csv", stringsAsFactors=F)
# test_data <- read.csv("test.csv", stringsAsFactors=F)
# train_ids <- 1:nrow(train_data)
data_y <- data$revenue
data$revenue <- NULL
# data <- rbind(train_data, test_data)
# process Open.Date column
data$Open.Date <- as.Date(data$Open.Date, format="%m/%d/%Y")
data$opendate_numeric <- as.numeric(data$Open.Date)
data$opendate_month <- as.numeric(format(data$Open.Date, "%m"))
data$opendate_day <- as.numeric(format(data$Open.Date, "%d"))
data$opendate_year <- as.numeric(format(data$Open.Date, "%Y"))
# add features based on City.Group, Type
data <- dichotomize(data, "City.Group")
data$Type <- ifelse(data$Type == "DT" | data$Type == "MB", "Other", data$Type)
data <- dichotomize(data, "Type")
data$instabul <- ifelse(data$City=="İstanbul", 1, 0)
data$ankara <- ifelse(data$City=="Ankara", 1, 0)
pcols <- paste0("P", 1:37)
for (var in pcols){
data <- dichotomize(data, var)
}
# collect columns with many zeros
zero_cols <- paste0("P", c(14:18, 24:27, 29:37))
# set zeros as NA
for (var in zero_cols){
data[, var] <- ifelse(data[, var]==0, NA, data[, var])
}
# create features for missingness
for (var in zero_cols){
data[, paste0(var, "is0")] <- ifelse(is.na(data[, var]), 1, 0)
}
# columns used to predict missing values
impute_pred_cols <- names(data[, 44:53])
set.seed(1)
for (var in zero_cols){ # for each columns with missing data
test_rows <- which(is.na(data[, var])) # index rows with missing data
train_rows <- (1:nrow(data))[-test_rows] # index rows with no missing data
rf_imp <- randomForest(y=data[train_rows, var], x=data[train_rows, impute_pred_cols], do.trace=50) #train random forest on observed data
imputed_values <- predict(rf_imp, newdata=data[test_rows, impute_pred_cols]) # predict missing data
data[test_rows, var] <- imputed_values # replace missing values with predictions
}
is0feats <- names(data)[str_detect(names(data), "is0")]
data$num0s <- apply(data[,is0feats], 1, sum)
pcols <- paste0("P", 1:37)
# impute_cols <- names(data[, c(6:42, 44:54)])
# data_imputed <- preProcess(data[, impute_cols], method="bagImpute")
for (var in pcols){
data[, paste0("log_", var)] <- log(data[, var] + 1)
}
data_x <- data[, c(6:ncol(data))]
# model training
set.seed(1)
# train_grid <- expand.grid(.mtry = seq(2, ncol(data_x), 1))
train_grid <- expand.grid(.mtry = 250)
train_params <- trainControl(method = "cv",
number = 50,
#                              repeats = 10,
savePredictions = TRUE,
summaryFunction = expRMSE,
verboseIter = TRUE)
train_model <- train(y = log(data_y),
x = data_x,
ntree=5000,
metric = "expRMSE",
maximize = FALSE,
tuneGrid = train_grid,
trControl = train_params)
train_model
setwd("~/Dropbox/kaggle/restaurant/")
source("~/Dropbox/mungekit.R")
library(randomForest)
library(caret)
library(doMC)
# library(imputeR)
library(Boruta)
registerDoMC(6)
data <- read.csv("train.csv", stringsAsFactors=F)
data_y <- data$revenue
data$revenue <- NULL
# process Open.Date column
data$Open.Date <- as.Date(data$Open.Date, format="%m/%d/%Y")
data$opendate_numeric <- as.numeric(data$Open.Date)
data$opendate_month <- as.numeric(format(data$Open.Date, "%m"))
data$opendate_day <- as.numeric(format(data$Open.Date, "%d"))
data$opendate_year <- as.numeric(format(data$Open.Date, "%Y"))
# add features based on City.Group, Type
data <- dichotomize(data, "City.Group")
data$Type <- ifelse(data$Type == "DT" | data$Type == "MB", "Other", data$Type)
data <- dichotomize(data, "Type")
data$instabul <- ifelse(data$City=="İstanbul", 1, 0)
data$ankara <- ifelse(data$City=="Ankara", 1, 0)
# expand all 'P' features to binary encodings
pcols <- paste0("P", 1:37)
for (var in pcols){
data <- dichotomize(data, var)
}
data_x <- data[, c(6:ncol(data))]
# model training
set.seed(1)
# train_grid <- expand.grid(.mtry = seq(2, ncol(data_x), 1))
train_grid <- expand.grid(.mtry = 250)
train_params <- trainControl(method = "cv",
number = 50,
#                              repeats = 10,
savePredictions = TRUE,
summaryFunction = expRMSE,
verboseIter = TRUE)
train_model <- train(y = log(data_y),
x = data_x,
ntree=5000,
metric = "expRMSE",
maximize = FALSE,
tuneGrid = train_grid,
trControl = train_params)
train_model
test_data <- read.csv("test.csv", stringsAsFactors=F)
test_data$Open.Date <- as.Date(test_data$Open.Date, format="%m/%d/%Y")
test_data$opendate_numeric <- as.numeric(test_data$Open.Date)
test_data$opendate_month <- as.numeric(format(test_data$Open.Date, "%m"))
test_data$opendate_day <- as.numeric(format(test_data$Open.Date, "%d"))
test_data$opendate_year <- as.numeric(format(test_data$Open.Date, "%Y"))
# add features based on City.Group, Type
test_data <- dichotomize(test_data, "City.Group")
test_data$Type <- ifelse(test_data$Type == "DT" | test_data$Type == "MB", "Other", test_data$Type)
test_data <- dichotomize(test_data, "Type")
test_data$instabul <- ifelse(test_data$City=="İstanbul", 1, 0)
test_data$ankara <- ifelse(test_data$City=="Ankara", 1, 0)
pcols <- paste0("P", 1:37)
for (var in pcols){
test_data <- dichotomize(test_data, var)
}
test_data_x <- test_data[, names(data_x)]
train_data <- read.csv("train.csv", stringsAsFactors=F)
test_data <- read.csv("test.csv", stringsAsFactors=F)
data_y <- train_data$revenue
train_data$revenue <- NULL
data <- rbind(train_data, test_data)
train_cols <- 1:nrow(train_data)
test_cols <- (nrow(train_data)+1):nrow(data)
train_cols
head(test_cols)
tail(test_cols)
train_index <- 1:nrow(train_data)
test_index <- (nrow(train_data)+1):nrow(data)
data$Open.Date <- as.Date(data$Open.Date, format="%m/%d/%Y")
data$opendate_numeric <- as.numeric(data$Open.Date)
data$opendate_month <- as.numeric(format(data$Open.Date, "%m"))
data$opendate_day <- as.numeric(format(data$Open.Date, "%d"))
data$opendate_year <- as.numeric(format(data$Open.Date, "%Y"))
# add features based on City.Group, Type
data <- dichotomize(data, "City.Group")
data$Type <- ifelse(data$Type == "DT" | data$Type == "MB", "Other", data$Type)
data <- dichotomize(data, "Type")
data$instabul <- ifelse(data$City=="İstanbul", 1, 0)
data$ankara <- ifelse(data$City=="Ankara", 1, 0)
# expand all 'P' features to binary encodings
pcols <- paste0("P", 1:37)
for (var in pcols){
data <- dichotomize(data, var)
}
train_data_x <- data[train_index, c(6:ncol(data))]
test_data_x <- data[test_index, c(6:ncol(data))]
set.seed(1)
train_grid <- expand.grid(.mtry = seq(25, ncol(data_x), 100))
train_params <- trainControl(method = "cv",
number = 5,
#                               repeats = 5,
savePredictions = TRUE,
summaryFunction = expRMSE,
verboseIter = TRUE)
train_model <- train(y = log(data_y),
x = train_data_x,
ntree=100,
metric = "expRMSE",
maximize = FALSE,
tuneGrid = train_grid,
trControl = train_params)
train_model
train_model <- train(y = log(data_y),
x = train_data_x,
ntree=1000,
metric = "expRMSE",
maximize = FALSE,
tuneGrid = train_grid,
trControl = train_params)
train_model
set.seed(1)
train_grid <- expand.grid(.mtry = seq(25, ncol(data_x), 25))
# train_grid <- expand.grid(.mtry = 250)
train_params <- trainControl(method = "repeatedcv",
number = 50,
repeats = 5,
savePredictions = TRUE,
summaryFunction = expRMSE,
verboseIter = TRUE)
train_model <- train(y = log(data_y),
x = train_data_x,
ntree=5000,
metric = "expRMSE",
maximize = FALSE,
tuneGrid = train_grid,
trControl = train_params)
train_model
plot(train_model)
set.seed(1)
brut <- Boruta(y = data_y, x = data_x, maxRuns=500)
data_x <- data_x[, names(brut$finalDecision[brut$finalDecision != "Rejected"])]
brut
set.seed(1)
# train_grid <- expand.grid(.mtry = seq(2, ncol(data_x), 1))
train_grid <- expand.grid(.mtry = seq(2, ncol(data_x), 1))
train_params <- trainControl(method = "repeatedcv",
number = 50,
repeats = 5,
savePredictions = TRUE,
summaryFunction = expRMSE,
verboseIter = TRUE)
train_model <- train(y = log(data_y),
x = data_x,
ntree=5000,
metric = "expRMSE",
maximize = FALSE,
tuneGrid = train_grid,
trControl = train_params)
train_model
train_model$times
580/60
set.seed(1)
brut <- Boruta(y = data_y, x = train_data_x, maxRuns=500)
data_x <- data_x[, names(brut$finalDecision[brut$finalDecision != "Rejected"])]
train_data_x <- train_data_x[, names(brut$finalDecision[brut$finalDecision != "Rejected"])]
brut
set.seed(1)
# train_grid <- expand.grid(.mtry = seq(2, ncol(data_x), 1))
train_grid <- expand.grid(.mtry = seq(2, ncol(data_x), 1))
train_params <- trainControl(method = "repeatedcv",
number = 50,
repeats = 5,
savePredictions = TRUE,
summaryFunction = expRMSE,
verboseIter = TRUE)
train_model <- train(y = log(data_y),
x = data_x,
ntree=5000,
metric = "expRMSE",
maximize = FALSE,
tuneGrid = train_grid,
trControl = train_params)
plot(train_model)
train_model
train_data <- read.csv("train.csv", stringsAsFactors=F)
test_data <- read.csv("test.csv", stringsAsFactors=F)
data_y <- train_data$revenue
train_data$revenue <- NULL
data <- rbind(train_data, test_data)
train_index <- 1:nrow(train_data)
test_index <- (nrow(train_data)+1):nrow(data)
# process Open.Date column
data$Open.Date <- as.Date(data$Open.Date, format="%m/%d/%Y")
data$opendate_numeric <- as.numeric(data$Open.Date)
data$opendate_month <- as.numeric(format(data$Open.Date, "%m"))
data$opendate_day <- as.numeric(format(data$Open.Date, "%d"))
data$opendate_year <- as.numeric(format(data$Open.Date, "%Y"))
# add features based on City.Group, Type
data <- dichotomize(data, "City.Group")
data$Type <- ifelse(data$Type == "DT" | data$Type == "MB", "Other", data$Type)
data <- dichotomize(data, "Type")
data$instabul <- ifelse(data$City=="İstanbul", 1, 0)
data$ankara <- ifelse(data$City=="Ankara", 1, 0)
# expand all 'P' features to binary encodings
pcols <- paste0("P", 1:37)
for (var in pcols){
data <- dichotomize(data, var)
}
train_data_x <- data[train_index, c(6:ncol(data))]
test_data_x <- data[test_index, c(6:ncol(data))]
set.seed(1)
# train_grid <- expand.grid(.mtry = seq(25, ncol(train_data_x), 25))
train_grid <- expand.grid(.mtry = 225)
train_params <- trainControl(method = "cv",
number = 10,
#                              repeats = 5,
savePredictions = TRUE,
summaryFunction = expRMSE,
verboseIter = TRUE)
train_model <- train(y = log(data_y),
x = train_data_x,
ntree=5000,
metric = "expRMSE",
maximize = FALSE,
tuneGrid = train_grid,
trControl = train_params)
predictions <- predict(train_model, newdata=test_data_x)
pred.df <- data.frame(Id = test_data$Id,
Prediction = exp(predictions))
head(pred.df)
sub11 <- read.csv("submission11.csv")
plot(sub11$Prediction, pred.df$Prediction)
sub3 <- read.csv("submission3.csv")
plot(sub3$Prediction, pred.df$Prediction)
cor(sub11$Prediction, pred.df$Prediction)
cor(sub3$Prediction, pred.df$Prediction)
write.table(pred.df, "submission21.csv", sep=",", col.names=T, row.names=F)
train_grid <- expand.grid(.n.trees = seq(100, 5000, 100),
.interaction.depth = seq(1, 15, 2),
.shrinkage = c(.01 ,.001, .0001))
train_grid <- expand.grid(.n.trees = seq(100, 2000, 100),
.interaction.depth = seq(1, 15, 2),
.shrinkage = c(.1 ,.01, .001))
train_params <- trainControl(method = "repeatedcv",
number = 10,
repeats = 3,
savePredictions = TRUE,
summaryFunction = expRMSE,
verboseIter = TRUE)
train_model <- train(y = data_y,
x = train_data_x,
distribution = "gaussian",
method = "gbm",
metric = "expRMSE",
maximize = FALSE,
tuneGrid = train_grid,
trControl = train_params)
train_model
train_grid <- expand.grid(.n.trees = seq(100, 500, 100),
.interaction.depth = seq(1, 3, 2),
.shrinkage = c(.1 ,.01, .001))
train_params <- trainControl(method = "cv",
number = 5,
#                              repeats = 3,
savePredictions = TRUE,
summaryFunction = expRMSE,
verboseIter = TRUE)
train_model <- train(y = data_y,
x = train_data_x,
distribution = "gaussian",
method = "gbm",
metric = "expRMSE",
maximize = FALSE,
tuneGrid = train_grid,
trControl = train_params)
summary(train_datA_x)
summary(train_data_x)
any(is.na(train_data_x))
train_params <- trainControl(method = "cv",
number = 5,
#                              repeats = 3,
#                              savePredictions = TRUE,
summaryFunction = expRMSE,
verboseIter = TRUE)
train_model <- train(y = data_y,
x = train_data_x,
distribution = "gaussian",
method = "gbm",
metric = "expRMSE",
maximize = FALSE,
tuneGrid = train_grid,
trControl = train_params)
train_params <- trainControl(method = "cv",
number = 5,
#                              repeats = 3,
#                              savePredictions = TRUE,
summaryFunction = expRMSE,
verboseIter = TRUE)
train_model <- train(y = log(data_y),
x = train_data_x,
distribution = "gaussian",
method = "gbm",
metric = "expRMSE",
maximize = FALSE,
tuneGrid = train_grid,
trControl = train_params)
warnings()
train_model
plot(train_model)
train_grid <- expand.grid(.n.trees = seq(100, 3000, 100),
.interaction.depth = seq(1, 15, 2),
.shrinkage = c(.1 ,.01, .001))
train_grid <- expand.grid(.n.trees = seq(100, 3000, 100),
.interaction.depth = seq(1, 15, 2),
.shrinkage = c(.1 ,.01, .001))
# train_grid <- expand.grid(.n.trees = 300,
#                           .interaction.depth = 3,
#                           .shrinkage = .01)
train_params <- trainControl(method = "repeatedcv",
number = 10,
repeats = 5,
savePredictions = TRUE,
summaryFunction = expRMSE,
verboseIter = TRUE)
train_model <- train(y = log(data_y),
x = train_data_x,
distribution = "gaussian",
method = "gbm",
metric = "expRMSE",
maximize = FALSE,
tuneGrid = train_grid,
trControl = train_params)
plot(train_model)
train_params <- trainControl(
method = "cv",
number = 10,
index = createFolds(data_y, k=10),
savePredictions = TRUE,
summaryFunction = expRMSE,
verboseIter = TRUE)
model_list <- caretList(y=log(data_y),
x=train_data_x,
metric = 'expRMSE',
trControl = train_params,
tuneList=list(
rf=caretModelSpec(method='rf', ntree=5000, tuneGrid=expand.grid(.mtry=c(225))),
gbm=caretModelSpec(method='gbm', tuneGrid=data.frame(.n.trees=200, .interaction.depth=11, .shrinkage=c(.01)))))
# model training
library(caretEnsemble)
model_list <- caretList(y=log(data_y),
x=train_data_x,
metric = 'expRMSE',
trControl = train_params,
tuneList=list(
rf=caretModelSpec(method='rf', ntree=5000, tuneGrid=expand.grid(.mtry=c(225))),
gbm=caretModelSpec(method='gbm', tuneGrid=data.frame(.n.trees=200, .interaction.depth=11, .shrinkage=c(.01)))))
#
model_list
train_params <- trainControl(
method = "cv",
number = 10,
index = createFolds(log(data_y) k=10),
savePredictions = TRUE,
summaryFunction = expRMSE,
verboseIter = TRUE)
train_params <- trainControl(
method = "cv",
number = 10,
index = createFolds(log(data_y), k=10),
savePredictions = TRUE,
summaryFunction = expRMSE,
verboseIter = TRUE)
model_list <- caretList(y=log(data_y),
x=train_data_x,
metric = 'expRMSE',
trControl = train_params,
tuneList=list(
rf=caretModelSpec(method='rf', ntree=5000, tuneGrid=expand.grid(.mtry=c(225))),
gbm=caretModelSpec(method='gbm', tuneGrid=data.frame(.n.trees=200, .interaction.depth=11, .shrinkage=c(.01)))))
#
train_params <- trainControl(
method = "cv",
number = 10,
index = createFolds(log(data_y), k=10),
#                   savePredictions = TRUE,
#                   summaryFunction = expRMSE,
verboseIter = TRUE)
model_list <- caretList(y=log(data_y),
x=train_data_x,
#                         metric = 'expRMSE',
trControl = train_params,
tuneList=list(
rf=caretModelSpec(method='rf', ntree=5000, tuneGrid=expand.grid(.mtry=c(225))),
gbm=caretModelSpec(method='gbm', tuneGrid=data.frame(.n.trees=200, .interaction.depth=11, .shrinkage=c(.01)))))
#
log_data_y <- log(data_y)
train_params <- trainControl(
method = "cv",
number = 10,
index = createFolds(log_data_y), k=10),
#                   savePredictions = TRUE,
#                   summaryFunction = expRMSE,
verboseIter = TRUE)
train_params <- trainControl(
method = "cv",
number = 10,
index = createFolds(log_data_y, k=10),
#                   savePredictions = TRUE,
#                   summaryFunction = expRMSE,
verboseIter = TRUE)
model_list <- caretList(y=log_data_y),
x=train_data_x,
#                         metric = 'expRMSE',
trControl = train_params,
tuneList=list(
rf=caretModelSpec(method='rf', ntree=5000, tuneGrid=expand.grid(.mtry=c(225))),
gbm=caretModelSpec(method='gbm', tuneGrid=data.frame(.n.trees=200, .interaction.depth=11, .shrinkage=c(.01)))))
#
model_list <- caretList(y=log_data_y,
x=train_data_x,
#                         metric = 'expRMSE',
trControl = train_params,
tuneList=list(
rf=caretModelSpec(method='rf', ntree=5000, tuneGrid=expand.grid(.mtry=c(225))),
gbm=caretModelSpec(method='gbm', tuneGrid=data.frame(.n.trees=200, .interaction.depth=11, .shrinkage=c(.01)))))
#
